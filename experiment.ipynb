{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (1.25.3)\n",
      "Requirement already satisfied: faiss-cpu in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: langchain_nvidia_ai_endpoints in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (0.3.9)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from langchain_nvidia_ai_endpoints) (3.11.12)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from langchain_nvidia_ai_endpoints) (0.3.35)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (1.18.3)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (0.3.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (2.10.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (3.10.15)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (2.27.2)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (3.10)\n",
      "Requirement already satisfied: anyio in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (4.8.0)\n",
      "Requirement already satisfied: certifi in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (1.3.1)\n",
      "Collecting langchain_groq\n",
      "  Downloading langchain_groq-0.2.4-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
      "  Downloading groq-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from langchain_groq) (0.3.35)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.8.0)\n",
      "Collecting distro<2,>=1.7.0 (from groq<1,>=0.4.1->langchain_groq)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_groq) (0.3.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_groq) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_groq) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_groq) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_groq) (24.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain_groq) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_groq) (3.10.15)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_groq) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_groq) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_groq) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_groq) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\jony\\projects\\ongoing\\doc-chat\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_groq) (2.3.0)\n",
      "Downloading langchain_groq-0.2.4-py3-none-any.whl (14 kB)\n",
      "Downloading groq-0.18.0-py3-none-any.whl (121 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: distro, groq, langchain_groq\n",
      "Successfully installed distro-1.9.0 groq-0.18.0 langchain_groq-0.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf\n",
    "!pip install faiss-cpu\n",
    "!pip install langchain_nvidia_ai_endpoints\n",
    "!pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.pdf import PyMuPDFLoader\n",
    "from langchain_text_splitters.character import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 25 chunks\n"
     ]
    }
   ],
   "source": [
    "loader = PyMuPDFLoader('./pdfs/sd.pdf')\n",
    "pages = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=100)\n",
    "chunks = splitter.split_documents(pages)\n",
    "print(f\"Split into {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Designing Instagram\n",
      "Let's design a photo-sharing service like Instagram, where users can upload photos to share them with \n",
      "other users. Similar Services: Flickr, Picasa Difficulty Level: Medium\n",
      "1. What is Instagram?\n",
      "Instagram is a social networking service which enables its users to upload and share their photos and \n",
      "videos with other users. Instagram users can choose to share information either publicly or privately.' metadata={'producer': 'iLovePDF', 'creator': '', 'creationdate': '', 'source': './pdfs/sd.pdf', 'file_path': './pdfs/sd.pdf', 'total_pages': 6, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-02-15T04:25:03+00:00', 'trapped': '', 'modDate': 'D:20250215042503Z', 'creationDate': '', 'page': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Designing Instagram\\nLet's design a photo-sharing service like Instagram, where users can upload photos to share them with \\nother users. Similar Services: Flickr, Picasa Difficulty Level: Medium\\n1. What is Instagram?\\nInstagram is a social networking service which enables its users to upload and share their photos and \\nvideos with other users. Instagram users can choose to share information either publicly or privately.\",\n",
       " 'Anything shared publicly can be seen by any other user, whereas privately shared content can only be \\naccessed by a specified set of people. Instagram also enables its users to share through many other \\nsocial networking platforms, such as Facebook, Twitter, Flickr, and Tumblr.\\nFor the sake of this exercise, we plan to design a simpler version of Instagram, where a user can share \\nphotos and can also follow other users. The ‘News Feed’ for each user will consist of top photos of all',\n",
       " 'the people the user follows.\\n2. Requirements and Goals of the System\\nWe’ll focus on the following set of requirements while designing the Instagram:\\nFunctional Requirements\\n1. Users should be able to upload/download/view photos. \\n2. Users can perform searches based on photo/video titles. \\n3. Users can follow other users. \\n4. The system should be able to generate and display a user’s News Feed consisting of top photos \\nfrom all the people the user follows. \\nNon-functional Requirements',\n",
       " 'from all the people the user follows. \\nNon-functional Requirements\\n1. Our service needs to be highly available. \\n2. The acceptable latency of the system is 200ms for News Feed generation. \\n3. Consistency can take a hit (in the interest of availability), if a user doesn’t see a photo for a \\nwhile; it should be fine. \\n4. The system should be highly reliable; any uploaded photo or video should never be lost. \\nNot in scope: Adding tags to photos, searching photos on tags, commenting on photos, tagging users to',\n",
       " 'photos, who to follow, etc.\\n3. Some Design Considerations\\nThe system would be read-heavy, so we will focus on building a system that can retrieve photos \\nquickly.\\n1. Practically, users can upload as many photos as they like. Efficient management of storage \\nshould be a crucial factor while designing this system.',\n",
       " '2. Low latency is expected while viewing photos. \\n3. Data should be 100% reliable. If a user uploads a photo, the system will guarantee that it will \\nnever be lost. \\n4. Capacity Estimation and Constraints\\n•\\nLet’s assume we have 500M total users, with 1M daily active users. \\n•\\n2M new photos every day, 23 new photos every second. \\n•\\nAverage photo file size => 200KB \\n•\\nTotal space required for 1 day of photos \\n2M * 200KB => 400 GB \\n•\\nTotal space required for 10 years:',\n",
       " '2M * 200KB => 400 GB \\n•\\nTotal space required for 10 years: \\n400GB * 365 (days a year) * 10 (years) ~= 1425TB \\n5. High Level System Design\\nAt a high-level, we need to support two scenarios, one to upload photos and the other to view/search \\nphotos. Our service would need some object storage servers to store photos and also some database \\nservers to store metadata information about the photos.\\n6. Database Schema',\n",
       " 'servers to store metadata information about the photos.\\n6. Database Schema\\n \\n�     Defining the DB schema in the early stages of the interview would help to understand the data\\nflow among various components and later would guide towards data partitioning. \\nWe need to store data about users, their uploaded photos, and people they follow. Photo table will store \\nall data related to a photo; we need to have an index on (PhotoID, CreationDate) since we need to fetch\\nrecent photos first.',\n",
       " 'A straightforward approach for storing the above schema would be to use an RDBMS like MySQL \\nsince we require joins. But relational databases come with their challenges, especially when we need to \\nscale them. For details, please take a look at SQL vs. NoSQL.\\nWe can store photos in a distributed file storage like HDFS or S3.\\nWe can store the above schema in a distributed key-value store to enjoy the benefits offered by NoSQL.',\n",
       " 'All the metadata related to photos can go to a table where the ‘key’ would be the ‘PhotoID’ and the \\n‘value’ would be an object containing PhotoLocation, UserLocation, CreationTimestamp, etc.\\nWe need to store relationships between users and photos, to know who owns which photo. We also \\nneed to store the list of people a user follows. For both of these tables, we can use a wide-column \\ndatastore like Cassandra. For the ‘UserPhoto’ table, the ‘key’ would be ‘UserID’ and the ‘value’ would',\n",
       " 'be the list of ‘PhotoIDs’ the user owns, stored in different columns. We will have a similar scheme for \\nthe ‘UserFollow’ table.\\nCassandra or key-value stores in general, always maintain a certain number of replicas to offer \\nreliability. Also, in such data stores, deletes don’t get applied instantly, data is retained for certain days \\n(to support undeleting) before getting removed from the system permanently.\\n7. Data Size Estimation',\n",
       " '(to support undeleting) before getting removed from the system permanently.\\n7. Data Size Estimation\\nLet’s estimate how much data will be going into each table and how much total storage we will need \\nfor 10 years.\\nUser: Assuming each “int” and “dateTime” is four bytes, each row in the User’s table will be of 68 \\nbytes:\\nUserID (4 bytes) + Name (20 bytes) + Email (32 bytes) + DateOfBirth (4 bytes) + CreationDate (4\\nbytes) + LastLogin (4 bytes) = 68 bytes',\n",
       " 'bytes) + LastLogin (4 bytes) = 68 bytes \\nIf we have 500 million users, we will need 32GB of total storage.\\n500 million * 68 ~= 32GB',\n",
       " 'Photo: Each row in Photo’s table will be of 284 bytes:\\nPhotoID (4 bytes) + UserID (4 bytes) + PhotoPath (256 bytes) + PhotoLatitude (4 bytes) +\\nPhotLongitude(4 bytes) + UserLatitude (4 bytes) + UserLongitude (4 bytes) + CreationDate (4 bytes) =\\n284 bytes \\nIf 2M new photos get uploaded every day, we will need 0.5GB of storage for one day:\\n2M * 284 bytes ~= 0.5GB per day \\nFor 10 years we will need 1.88TB of storage.',\n",
       " '2M * 284 bytes ~= 0.5GB per day \\nFor 10 years we will need 1.88TB of storage. \\nUserFollow: Each row in the UserFollow table will consist of 8 bytes. If we have 500 million users \\nand on average each user follows 500 users. We would need 1.82TB of storage for the UserFollow \\ntable:\\n500 million users * 500 followers * 8 bytes ~= 1.82TB \\nTotal space required for all tables for 10 years will be 3.7TB:\\n32GB + 1.88TB + 1.82TB ~= 3.7TB \\n8. Component Design',\n",
       " '32GB + 1.88TB + 1.82TB ~= 3.7TB \\n8. Component Design\\nPhoto uploads (or writes) can be slow as they have to go to the disk, whereas reads will be faster, \\nespecially if they are being served from cache.\\nUploading users can consume all the available connections, as uploading is a slow process. This means \\nthat ‘reads’ cannot be served if the system gets busy with all the write requests. We should keep in mind',\n",
       " 'that web servers have a connection limit before designing our system. If we assume that a web server \\ncan have a maximum of 500 connections at any time, then it can’t have more than 500 concurrent \\nuploads or reads. To handle this bottleneck we can split reads and writes into separate services. We will \\nhave dedicated servers for reads and different servers for writes to ensure that uploads don’t hog the \\nsystem.',\n",
       " 'system.\\nSeparating photos’ read and write requests will also allow us to scale and optimize each of these \\noperations independently.',\n",
       " '9. Reliability and Redundancy\\nLosing files is not an option for our service. Therefore, we will store multiple copies of each file so that\\nif one storage server dies we can retrieve the photo from the other copy present on a different storage \\nserver.\\nThis same principle also applies to other components of the system. If we want to have high availability\\nof the system, we need to have multiple replicas of services running in the system, so that if a few',\n",
       " 'services die down the system still remains available and running. Redundancy removes the single point \\nof failure in the system.\\nIf only one instance of a service is required to run at any point, we can run a redundant secondary copy \\nof the service that is not serving any traffic, but it can take control after the failover when primary has a\\nproblem.\\nCreating redundancy in a system can remove single points of failure and provide a backup or spare',\n",
       " 'Creating redundancy in a system can remove single points of failure and provide a backup or spare \\nfunctionality if needed in a crisis. For example, if there are two instances of the same service running in\\nproduction and one fails or degrades, the system can failover to the healthy copy. Failover can happen \\nautomatically or require manual intervention.',\n",
       " '10. Data Sharding\\nLet’s discuss different schemes for metadata sharding:\\na. Partitioning based on UserID Let’s assume we shard based on the ‘UserID’ so that we can keep all \\nphotos of a user on the same shard. If one DB shard is 1TB, we will need four shards to store 3.7TB of \\ndata. Let’s assume for better performance and scalability we keep 10 shards.\\nSo we’ll find the shard number by UserID % 10 and then store the data there. To uniquely identify any',\n",
       " 'photo in our system, we can append shard number with each PhotoID.\\nHow can we generate PhotoIDs? Each DB shard can have its own auto-increment sequence for \\nPhotoIDs and since we will append ShardID with each PhotoID, it will make it unique throughout our \\nsystem.\\nWhat are the different issues with this partitioning scheme?\\n1. How would we handle hot users? Several people follow such hot users and a lot of other people \\nsee any photo they upload.',\n",
       " 'see any photo they upload. \\n2. Some users will have a lot of photos compared to others, thus making a non-uniform \\ndistribution of storage. \\n3. What if we cannot store all pictures of a user on one shard? If we distribute photos of a user \\nonto multiple shards will it cause higher latencies? \\n4. Storing all photos of a user on one shard can cause issues like unavailability of all of the user’s \\ndata if that shard is down or higher latency if it is serving high load etc.',\n",
       " 'data if that shard is down or higher latency if it is serving high load etc. \\nb. Partitioning based on PhotoID If we can generate unique PhotoIDs first and then find a shard \\nnumber through “PhotoID % 10”, the above problems will have been solved. We would not need to \\nappend ShardID with PhotoID in this case as PhotoID will itself be unique throughout the system.']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(chunks[0])\n",
    "chunk_texts = [chunk.page_content for chunk in chunks]\n",
    "chunk_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "\n",
    "embeddings = NVIDIAEmbeddings(\n",
    "  model=\"nvidia/llama-3.2-nv-embedqa-1b-v2\", \n",
    "  api_key=\"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\", \n",
    "  truncate=\"END\", \n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50  # Matches NVIDIA's default max_batch_size\n",
    "texts = [chunk.page_content for chunk in chunks]\n",
    "metadatas = [chunk.metadata for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 25/25 [00:02<00:00,  9.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "progress_bar = tqdm_asyncio(total=len(texts), desc=\"Generating embeddings\")\n",
    "\n",
    "db = FAISS.from_texts([\"init\"], embeddings)\n",
    "\n",
    "try:\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        batch_metadatas = metadatas[i:i+batch_size]\n",
    "        \n",
    "        # Get embeddings using NVIDIA's async method\n",
    "        batch_embeddings = await embeddings.aembed_documents(batch_texts)\n",
    "        \n",
    "        # Add to FAISS with metadata\n",
    "        db.add_embeddings(\n",
    "            text_embeddings=list(zip(batch_texts, batch_embeddings)),\n",
    "            metadatas=batch_metadatas\n",
    "        )\n",
    "        \n",
    "        # Update progress\n",
    "        progress_bar.update(len(batch_texts))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing batch {i}: {str(e)}\")\n",
    "    raise\n",
    "finally:\n",
    "    progress_bar.close()\n",
    "\n",
    "db.save_local(f\"./database/sd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "\n",
    "os.environ['GROQ_API_KEY'] = \"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\"\n",
    "llm = ChatGroq(model='deepseek-r1-distill-llama-70b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "prompt_template = \"\"\"Below is an instruction that describes a task, paired with an context that provides further context.\n",
    "Write a response that appropriately completes the request. If you don't know the answer to a question, please don't share false information. Just say that the question is out of scope.\n",
    "\n",
    "### Instruction:\n",
    "You are an electrical engineer and you will answer questions related to electrical engineering from the uploaded pdf context.\n",
    "\n",
    "### Context:\n",
    "{context}\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'The system being designed is an Instagram-like platform focused on photo sharing. It is tailored for a social media application where users can upload, download, view, and search for photos, follow other users, and view a news feed. The design emphasizes handling a high volume of data efficiently, with considerations for separating read and write operations to manage server load and ensure quick retrieval of photos. The system is designed to scale, managing storage effectively and ensuring a smooth user experience.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import re\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "class RemoveChainOfThoughtOutputParser(StrOutputParser):\n",
    "    def parse(self, text: str) -> str:\n",
    "        # Remove everything between <think> and </think> (including the tags)\n",
    "        cleaned_text = re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL)\n",
    "        return cleaned_text.strip()\n",
    "\n",
    "try:\n",
    "   new_db = FAISS.load_local(f\"./database/sd\", embeddings, allow_dangerous_deserialization=True)\n",
    "except FileNotFoundError as file_err:\n",
    "    print(f\"File not found: {str(file_err)}\")\n",
    "    raise\n",
    "\n",
    "# initialize the RAG Chain\n",
    "retriever = new_db.as_retriever()\n",
    "rag_chain = (\n",
    "  {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "  | prompt\n",
    "  | llm\n",
    "  | RemoveChainOfThoughtOutputParser()\n",
    ")\n",
    "\n",
    "# try:\n",
    "query = \"What are we designing here?\"\n",
    "# This will automatically pass the query to both the retriever and the question slot.\n",
    "answer = rag_chain.invoke(query)\n",
    "print({'answer': answer})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"./database/sd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-multipart\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: python-multipart\n",
      "Successfully installed python-multipart-0.0.20\n"
     ]
    }
   ],
   "source": [
    "!pip install python-multipart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
